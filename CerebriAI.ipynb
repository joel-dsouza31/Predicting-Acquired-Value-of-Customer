{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for plotting graphs\n",
    "import seaborn as sns # for plotting graphs\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#import libraries\n",
    "from datetime import datetime, timedelta,date\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('shop_data_cerebri.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>chain</th>\n",
       "      <th>dept</th>\n",
       "      <th>category</th>\n",
       "      <th>company</th>\n",
       "      <th>brand</th>\n",
       "      <th>date</th>\n",
       "      <th>productsize</th>\n",
       "      <th>productmeasure</th>\n",
       "      <th>purchasequantity</th>\n",
       "      <th>purchaseamount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86246</td>\n",
       "      <td>205</td>\n",
       "      <td>7</td>\n",
       "      <td>707</td>\n",
       "      <td>1078778070</td>\n",
       "      <td>12564.0</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>OZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>86246</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>6319</td>\n",
       "      <td>107654575</td>\n",
       "      <td>17876.0</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>64.0</td>\n",
       "      <td>OZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>86246</td>\n",
       "      <td>205</td>\n",
       "      <td>97</td>\n",
       "      <td>9753</td>\n",
       "      <td>1022027929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>86246</td>\n",
       "      <td>205</td>\n",
       "      <td>25</td>\n",
       "      <td>2509</td>\n",
       "      <td>107996777</td>\n",
       "      <td>31373.0</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>16.0</td>\n",
       "      <td>OZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>86246</td>\n",
       "      <td>205</td>\n",
       "      <td>55</td>\n",
       "      <td>5555</td>\n",
       "      <td>107684070</td>\n",
       "      <td>32094.0</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>16.0</td>\n",
       "      <td>OZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id  chain  dept  category     company    brand        date  \\\n",
       "0           0  86246    205     7       707  1078778070  12564.0  2012-03-02   \n",
       "1           1  86246    205    63      6319   107654575  17876.0  2012-03-02   \n",
       "2           2  86246    205    97      9753  1022027929      0.0  2012-03-02   \n",
       "3           3  86246    205    25      2509   107996777  31373.0  2012-03-02   \n",
       "4           4  86246    205    55      5555   107684070  32094.0  2012-03-02   \n",
       "\n",
       "   productsize productmeasure  purchasequantity  purchaseamount  \n",
       "0         12.0             OZ               1.0            7.59  \n",
       "1         64.0             OZ               1.0            1.59  \n",
       "2          1.0             CT               1.0            5.99  \n",
       "3         16.0             OZ               1.0            1.99  \n",
       "4         16.0             OZ               2.0           10.38  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1150000 entries, 0 to 1149999\n",
      "Data columns (total 12 columns):\n",
      "Unnamed: 0          1150000 non-null int64\n",
      "id                  1150000 non-null int64\n",
      "chain               1150000 non-null int64\n",
      "dept                1150000 non-null int64\n",
      "category            1150000 non-null int64\n",
      "company             1150000 non-null int64\n",
      "brand               1072497 non-null float64\n",
      "date                1150000 non-null object\n",
      "productsize         1150000 non-null float64\n",
      "productmeasure      1135067 non-null object\n",
      "purchasequantity    1149948 non-null float64\n",
      "purchaseamount      1149697 non-null float64\n",
      "dtypes: float64(4), int64(6), object(2)\n",
      "memory usage: 105.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows with no customer ID\n",
    "data= data[pd.notnull(data['id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = ['chain', 'dept', 'category', 'brand', 'productmeasure']\n",
    "NUMERIC_FEATURES = ['log_calibration_value']\n",
    "\n",
    "ALL_FEATURES = CATEGORICAL_FEATURES + NUMERIC_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.query('purchaseamount>0')\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "    #df['start_date'] = df.groupby('id')['date'].transform('min')\n",
    "    #df['end_date'] = df.groupby('id')['date'].transform('max')\n",
    "\n",
    "    # Specify data types\n",
    "    df['chain'] = (df['chain'].astype('category'))\n",
    "    df['dept'] = (df['dept'].astype('category'))\n",
    "    df['brand'] = (df['brand'].astype('category'))\n",
    "    df['category'] = (df['category'].astype('category'))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>chain</th>\n",
       "      <th>dept</th>\n",
       "      <th>category</th>\n",
       "      <th>company</th>\n",
       "      <th>brand</th>\n",
       "      <th>date</th>\n",
       "      <th>productsize</th>\n",
       "      <th>productmeasure</th>\n",
       "      <th>purchasequantity</th>\n",
       "      <th>purchaseamount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86246</td>\n",
       "      <td>205</td>\n",
       "      <td>7</td>\n",
       "      <td>707</td>\n",
       "      <td>1078778070</td>\n",
       "      <td>12564.0</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>OZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>86246</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>6319</td>\n",
       "      <td>107654575</td>\n",
       "      <td>17876.0</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>64.0</td>\n",
       "      <td>OZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>86246</td>\n",
       "      <td>205</td>\n",
       "      <td>97</td>\n",
       "      <td>9753</td>\n",
       "      <td>1022027929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>86246</td>\n",
       "      <td>205</td>\n",
       "      <td>25</td>\n",
       "      <td>2509</td>\n",
       "      <td>107996777</td>\n",
       "      <td>31373.0</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>16.0</td>\n",
       "      <td>OZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>86246</td>\n",
       "      <td>205</td>\n",
       "      <td>55</td>\n",
       "      <td>5555</td>\n",
       "      <td>107684070</td>\n",
       "      <td>32094.0</td>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>16.0</td>\n",
       "      <td>OZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id chain dept category     company    brand       date  \\\n",
       "0           0  86246   205    7      707  1078778070  12564.0 2012-03-02   \n",
       "1           1  86246   205   63     6319   107654575  17876.0 2012-03-02   \n",
       "2           2  86246   205   97     9753  1022027929      0.0 2012-03-02   \n",
       "3           3  86246   205   25     2509   107996777  31373.0 2012-03-02   \n",
       "4           4  86246   205   55     5555   107684070  32094.0 2012-03-02   \n",
       "\n",
       "   productsize productmeasure  purchasequantity  purchaseamount  \n",
       "0         12.0             OZ               1.0            7.59  \n",
       "1         64.0             OZ               1.0            1.59  \n",
       "2          1.0             CT               1.0            5.99  \n",
       "3         16.0             OZ               1.0            1.99  \n",
       "4         16.0             OZ               2.0           10.38  "
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Segmentation\n",
    "\n",
    "We use the <b> RFM </b> Recency-Frequency-Monetary method to segment our customers into 3 groups :\n",
    "\n",
    "<p><b>Low Value:</b> Customers who are less active than others, not very frequent buyer/visitor and generates very low - zero - maybe negative revenue.\n",
    "<p><b>Mid Value:</b> In the middle of everything. Often using our platform (but not as much as our High Values), fairly frequent and generates moderate revenue.\n",
    "<p><b>High Value:</b> The group we donâ€™t want to lose. High Revenue, Frequency and low Inactivity.\n",
    "    <p> We will take data of 2011, calculate RFM and use it for predicting next year. So we need to create two dataframes first and append RFM scores to them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2012-03-02 00:00:00'), Timestamp('2013-07-23 00:00:00'))"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date'].min(), data['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 2012 and 2013 dataframes\n",
    "df2012 = data[(data.date < date(2013,1,1))].reset_index(drop=True)\n",
    "df2013 = data[(data.date >= date(2013,1,1)) ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user dataframe for assigning clustering\n",
    "user = pd.DataFrame(df2012['id'].unique())\n",
    "user.columns = ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order cluster method\n",
    "def order_cluster(cluster_field_name, target_field_name,df,ascending):\n",
    "    new_cluster_field_name = 'new_' + cluster_field_name\n",
    "    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()\n",
    "    df_new = df_new.sort_values(by=target_field_name,ascending=ascending).reset_index(drop=True)\n",
    "    df_new['index'] = df_new.index\n",
    "    df_final = pd.merge(df,df_new[[cluster_field_name,'index']], on=cluster_field_name)\n",
    "    df_final = df_final.drop([cluster_field_name],axis=1)\n",
    "    df_final = df_final.rename(columns={\"index\":cluster_field_name})\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We came use of K-Means clustering to segment the customers into high, medium, or low value and to calculate the respective RFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate recency score\n",
    "max_purchase = df2012.groupby('id').date.max().reset_index()\n",
    "max_purchase.columns = ['id','MaxPurchaseDate']\n",
    "max_purchase['Recency'] = (max_purchase['MaxPurchaseDate'].max() - max_purchase['MaxPurchaseDate']).dt.days\n",
    "user = pd.merge(user, max_purchase[['id','Recency']], on='id')\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(user[['Recency']])\n",
    "user['RecencyCluster'] = kmeans.predict(user[['Recency']])\n",
    "\n",
    "user = order_cluster('RecencyCluster', 'Recency',user,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcuate frequency score\n",
    "frequency = df2012.groupby('id').date.count().reset_index()\n",
    "frequency.columns = ['id','Frequency']\n",
    "user = pd.merge(user, frequency, on='id')\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(user[['Frequency']])\n",
    "user['FrequencyCluster'] = kmeans.predict(user[['Frequency']])\n",
    "\n",
    "user = order_cluster('FrequencyCluster', 'Frequency',user,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcuate revenue score\n",
    "df2012['Revenue'] = df2012['purchasequantity'] * df2012['purchaseamount']\n",
    "revenue = df2012.groupby('id').Revenue.sum().reset_index()\n",
    "user = pd.merge(user, revenue, on='id')\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(user[['Revenue']])\n",
    "user['RevenueCluster'] = kmeans.predict(user[['Revenue']])\n",
    "user = order_cluster('RevenueCluster', 'Revenue',user,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall scoring\n",
    "user['OverallScore'] = user['RecencyCluster'] + user['FrequencyCluster'] + user['RevenueCluster']\n",
    "user['Segment'] = 'Low-Value'\n",
    "user.loc[user['OverallScore']>2,'Segment'] = 'Mid-Value' \n",
    "user.loc[user['OverallScore']>4,'Segment'] = 'High-Value' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Recency</th>\n",
       "      <th>RecencyCluster</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>FrequencyCluster</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>RevenueCluster</th>\n",
       "      <th>OverallScore</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86246</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4350</td>\n",
       "      <td>3</td>\n",
       "      <td>28208.35</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>High-Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86252</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4950</td>\n",
       "      <td>3</td>\n",
       "      <td>31395.90</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>High-Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67957375</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>879</td>\n",
       "      <td>1</td>\n",
       "      <td>27614.09</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>High-Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96664186</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>688</td>\n",
       "      <td>1</td>\n",
       "      <td>23906.39</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>High-Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96648193</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>62244.69</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>High-Value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  Recency  RecencyCluster  Frequency  FrequencyCluster   Revenue  \\\n",
       "0     86246        0               3       4350                 3  28208.35   \n",
       "1     86252        0               3       4950                 3  31395.90   \n",
       "2  67957375        6               3        879                 1  27614.09   \n",
       "3  96664186        7               3        688                 1  23906.39   \n",
       "4  96648193        6               3        103                 0  62244.69   \n",
       "\n",
       "   RevenueCluster  OverallScore     Segment  \n",
       "0               3             9  High-Value  \n",
       "1               3             9  High-Value  \n",
       "2               3             7  High-Value  \n",
       "3               3             7  High-Value  \n",
       "4               3             6  High-Value  "
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Life Time Value of customers for 2013\n",
    "\n",
    "Since no cost is specified to acquire the customer, we consider revenue as the life time value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate revenue and create a new dataframe for it\n",
    "df2013['Revenue'] = df2013['purchasequantity'] * df2013['purchaseamount']\n",
    "user_2013 = df2013.groupby('id')['Revenue'].sum().reset_index()\n",
    "user_2013.columns = ['id','2013_Revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now merge our 2012 and 2013 dataframes and see how the revenues are affected in one year and figure out the change in customer behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(user, user_2013, on='id', how='left')\n",
    "merge = merge.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Recency</th>\n",
       "      <th>RecencyCluster</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>FrequencyCluster</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>RevenueCluster</th>\n",
       "      <th>OverallScore</th>\n",
       "      <th>Segment</th>\n",
       "      <th>2013_Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86246</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4350</td>\n",
       "      <td>3</td>\n",
       "      <td>28208.35</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>High-Value</td>\n",
       "      <td>61278.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86252</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4950</td>\n",
       "      <td>3</td>\n",
       "      <td>31395.90</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>High-Value</td>\n",
       "      <td>73187.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67957375</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>879</td>\n",
       "      <td>1</td>\n",
       "      <td>27614.09</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>High-Value</td>\n",
       "      <td>3805.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96664186</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>688</td>\n",
       "      <td>1</td>\n",
       "      <td>23906.39</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>High-Value</td>\n",
       "      <td>3783.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96648193</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>62244.69</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>High-Value</td>\n",
       "      <td>142125.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  Recency  RecencyCluster  Frequency  FrequencyCluster   Revenue  \\\n",
       "0     86246        0               3       4350                 3  28208.35   \n",
       "1     86252        0               3       4950                 3  31395.90   \n",
       "2  67957375        6               3        879                 1  27614.09   \n",
       "3  96664186        7               3        688                 1  23906.39   \n",
       "4  96648193        6               3        103                 0  62244.69   \n",
       "\n",
       "   RevenueCluster  OverallScore     Segment  2013_Revenue  \n",
       "0               3             9  High-Value      61278.58  \n",
       "1               3             9  High-Value      73187.73  \n",
       "2               3             7  High-Value       3805.94  \n",
       "3               3             7  High-Value       3783.07  \n",
       "4               3             6  High-Value     142125.54  "
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use K-Means clustering to classify our customers to 3 segments:\n",
    "<li> Low LTV</li>\n",
    "    <li>Medium LTV</li>\n",
    "   <li>High LTV</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTVCluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>691.0</td>\n",
       "      <td>1001.485456</td>\n",
       "      <td>516.606750</td>\n",
       "      <td>0.00</td>\n",
       "      <td>569.470</td>\n",
       "      <td>980.46</td>\n",
       "      <td>1428.6900</td>\n",
       "      <td>1971.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366.0</td>\n",
       "      <td>2941.647978</td>\n",
       "      <td>665.798628</td>\n",
       "      <td>1976.76</td>\n",
       "      <td>2338.945</td>\n",
       "      <td>2812.24</td>\n",
       "      <td>3474.8625</td>\n",
       "      <td>4394.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135.0</td>\n",
       "      <td>5853.103852</td>\n",
       "      <td>1289.119058</td>\n",
       "      <td>4416.74</td>\n",
       "      <td>4924.100</td>\n",
       "      <td>5413.27</td>\n",
       "      <td>6398.8550</td>\n",
       "      <td>9790.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count         mean          std      min       25%      50%  \\\n",
       "LTVCluster                                                                \n",
       "0           691.0  1001.485456   516.606750     0.00   569.470   980.46   \n",
       "1           366.0  2941.647978   665.798628  1976.76  2338.945  2812.24   \n",
       "2           135.0  5853.103852  1289.119058  4416.74  4924.100  5413.27   \n",
       "\n",
       "                  75%      max  \n",
       "LTVCluster                      \n",
       "0           1428.6900  1971.55  \n",
       "1           3474.8625  4394.53  \n",
       "2           6398.8550  9790.13  "
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove outliers\n",
    "merge = merge[merge['2013_Revenue']<merge['2013_Revenue'].quantile(0.99)]\n",
    "\n",
    "\n",
    "#creating 3 clusters\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(merge[['2013_Revenue']])\n",
    "merge['LTVCluster'] = kmeans.predict(merge[['2013_Revenue']])\n",
    "\n",
    "#order cluster number based on LTV\n",
    "merge = order_cluster('LTVCluster', '2013_Revenue',merge,True)\n",
    "\n",
    "#creatinga new cluster dataframe\n",
    "cluster = merge.copy()\n",
    "\n",
    "#see details of the clusters\n",
    "cluster.groupby('LTVCluster')['2013_Revenue'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 2 is best with mean LTV 5853 and cluster 0 is worst with mean LTV 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We perform some steps to bring the data good enough to run our machine learning model on it and split the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categorical columns to numerical\n",
    "tx_class = pd.get_dummies(cluster)\n",
    "\n",
    "#create X and y, X will be feature set and y is the label - LTV\n",
    "X = tx_class.drop(['LTVCluster','2013_Revenue'],axis=1)\n",
    "y = tx_class['LTVCluster']\n",
    "\n",
    "#split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment is a categorical column that gets split to 0 and 1 notation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Recency</th>\n",
       "      <th>RecencyCluster</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>FrequencyCluster</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>RevenueCluster</th>\n",
       "      <th>OverallScore</th>\n",
       "      <th>Segment_High-Value</th>\n",
       "      <th>Segment_Low-Value</th>\n",
       "      <th>Segment_Mid-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>57426577</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>776</td>\n",
       "      <td>1</td>\n",
       "      <td>4327.21</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>93765042</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>4713.27</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>83679506</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>2221.05</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>75747032</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>423</td>\n",
       "      <td>0</td>\n",
       "      <td>4317.03</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>97177041</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>613</td>\n",
       "      <td>1</td>\n",
       "      <td>3252.98</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Recency  RecencyCluster  Frequency  FrequencyCluster  Revenue  \\\n",
       "177  57426577        1               3        776                 1  4327.21   \n",
       "252  93765042        1               3        711                 1  4713.27   \n",
       "792  83679506        0               3        496                 0  2221.05   \n",
       "304  75747032        7               3        423                 0  4317.03   \n",
       "595  97177041        8               2        613                 1  3252.98   \n",
       "\n",
       "     RevenueCluster  OverallScore  Segment_High-Value  Segment_Low-Value  \\\n",
       "177               1             5                   1                  0   \n",
       "252               1             5                   1                  0   \n",
       "792               0             3                   0                  0   \n",
       "304               1             4                   0                  0   \n",
       "595               0             3                   0                  0   \n",
       "\n",
       "     Segment_Mid-Value  \n",
       "177                  0  \n",
       "252                  0  \n",
       "792                  1  \n",
       "304                  1  \n",
       "595                  1  "
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LTVCluster            1.000000\n",
       "2013_Revenue          0.909347\n",
       "Revenue               0.667950\n",
       "RevenueCluster        0.661062\n",
       "OverallScore          0.646195\n",
       "Frequency             0.622719\n",
       "FrequencyCluster      0.602065\n",
       "Segment_High-Value    0.584978\n",
       "RecencyCluster        0.188703\n",
       "id                    0.037084\n",
       "Recency              -0.154482\n",
       "Segment_Low-Value    -0.288449\n",
       "Segment_Mid-Value    -0.348633\n",
       "Name: LTVCluster, dtype: float64"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate and show correlations\n",
    "corr_matrix = tx_class.corr()\n",
    "corr_matrix['LTVCluster'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the 2013 revenue with the 2012 RFM values are highly correlated to model our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = y\n",
    "unique, counts = np.unique(classes, return_counts=True)\n",
    "\n",
    "plt.bar(unique,counts)\n",
    "plt.title('Class Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows that the classes are imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start with XGBoost multiclass classifier to test the predictions of the data because of its speed  and regularized approach to take the most suitable variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGB classifier on training set: 0.90\n",
      "Accuracy of XGB classifier on test set: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90        35\n",
      "           1       0.65      0.69      0.67        16\n",
      "           2       0.71      0.56      0.63         9\n",
      "\n",
      "    accuracy                           0.80        60\n",
      "   macro avg       0.75      0.72      0.73        60\n",
      "weighted avg       0.80      0.80      0.80        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#XGBoost Multiclassification Model\n",
    "ltv_xgb_model = xgb.XGBClassifier(max_depth=5, learning_rate=0.1, gamma = 0 , objective= 'multi:softprob',\n",
    "                                  min_child_weight = 1, scale_pos_weight = 1\n",
    "                                  ,n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of XGB classifier on training set: {:.2f}'\n",
    "       .format(ltv_xgb_model.score(X_train, y_train)))\n",
    "print('Accuracy of XGB classifier on test set: {:.2f}'\n",
    "       .format(ltv_xgb_model.score(X_test, y_test)))\n",
    "\n",
    "y_pred = ltv_xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the training set\n",
    "\n",
    "This is done to rescale the values to mean 0 and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = X_train\n",
    "features_test = X_test\n",
    "target_train = y_train\n",
    "target_test = y_test\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create scale object\n",
    "scaler = StandardScaler()\n",
    "# Fit scaler to training data only\n",
    "scaler_fit = scaler.fit(features_train)\n",
    "# Transform both train and test data with the trained scaler\n",
    "X_train = scaler_fit.transform(features_train)\n",
    "X_test = scaler_fit.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Micro Average:  0.8000000000000002\n",
      "Test Accuracy:  0.8\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# Create XGB Classifier object\n",
    "xgb_clf = xgb.XGBClassifier(objective = \"multi:softmax\")\n",
    "# Fit model\n",
    "xgb_model = xgb_clf.fit(X_train, target_train)\n",
    "# Predictions\n",
    "y_train_preds = xgb_model.predict(X_train)\n",
    "y_test_preds = xgb_model.predict(X_test)\n",
    "# Print F1 scores and Accuracy\n",
    "#print(\"Training F1 Micro Average: \", f1_score(target_train, y_train_preds, average = \"micro\"))\n",
    "print(\"Test F1 Micro Average: \", f1_score(target_test, y_test_preds, average = \"micro\"))\n",
    "print(\"Test Accuracy: \", accuracy_score(target_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyperparameters to improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV] subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0, score=0.675, total=   0.4s\n",
      "[CV] subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0, score=0.781, total=   0.4s\n",
      "[CV] subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0, score=0.728, total=   0.4s\n",
      "[CV] subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0, score=0.684, total=   0.4s\n",
      "[CV] subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0, score=0.754, total=   0.4s\n",
      "[CV] subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0, score=0.746, total=   0.4s\n",
      "[CV] subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0, score=0.714, total=   0.4s\n",
      "[CV] subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0, score=0.679, total=   0.4s\n",
      "[CV] subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0, score=0.741, total=   0.4s\n",
      "[CV] subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.6, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=5, max_depth=2, learning_rate=0.1, gamma=1.5, colsample_bytree=1.0, score=0.679, total=   0.4s\n",
      "[CV] subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8, score=0.702, total=   0.4s\n",
      "[CV] subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8, score=0.772, total=   0.4s\n",
      "[CV] subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8, score=0.719, total=   0.4s\n",
      "[CV] subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8, score=0.667, total=   0.4s\n",
      "[CV] subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8, score=0.728, total=   0.4s\n",
      "[CV] subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8, score=0.754, total=   0.4s\n",
      "[CV] subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8, score=0.714, total=   0.4s\n",
      "[CV] subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8, score=0.688, total=   0.4s\n",
      "[CV] subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8, score=0.768, total=   0.4s\n",
      "[CV] subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8 \n",
      "[CV]  subsample=0.4, reg_lambda=4.5, reg_alpha=1, n_estimators=100, min_child_weight=1, max_depth=2, learning_rate=0.01, gamma=2, colsample_bytree=0.8, score=0.705, total=   0.4s\n",
      "[CV] subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0, score=0.702, total=   1.1s\n",
      "[CV] subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0, score=0.772, total=   0.8s\n",
      "[CV] subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0, score=0.702, total=   0.8s\n",
      "[CV] subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0, score=0.667, total=   0.9s\n",
      "[CV] subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0, score=0.737, total=   0.9s\n",
      "[CV] subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0, score=0.763, total=   0.9s\n",
      "[CV] subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0, score=0.732, total=   0.9s\n",
      "[CV] subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0, score=0.688, total=   0.9s\n",
      "[CV] subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0, score=0.759, total=   0.9s\n",
      "[CV] subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.2, reg_lambda=4.5, reg_alpha=0.5, n_estimators=250, min_child_weight=1, max_depth=2, learning_rate=0.001, gamma=0.5, colsample_bytree=1.0, score=0.696, total=   0.9s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0, score=0.693, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0, score=0.763, total=   0.7s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0, score=0.684, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0, score=0.632, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0, score=0.684, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0, score=0.728, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0, score=0.723, total=   0.7s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0, score=0.670, total=   0.8s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0, score=0.714, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0, n_estimators=100, min_child_weight=7, max_depth=4, learning_rate=0.1, gamma=0.1, colsample_bytree=1.0, score=0.670, total=   0.6s\n",
      "[CV] subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0, score=0.693, total=   3.3s\n",
      "[CV] subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0, score=0.807, total=   3.4s\n",
      "[CV] subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0, score=0.711, total=   3.4s\n",
      "[CV] subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0, score=0.667, total=   3.3s\n",
      "[CV] subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0, score=0.746, total=   3.4s\n",
      "[CV] subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0, score=0.754, total=   3.4s\n",
      "[CV] subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0, score=0.696, total=   3.4s\n",
      "[CV] subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0, score=0.679, total=   3.3s\n",
      "[CV] subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0, score=0.768, total=   3.4s\n",
      "[CV] subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.5, reg_lambda=4.5, reg_alpha=1, n_estimators=500, min_child_weight=7, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=1.0, score=0.688, total=   3.3s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6, score=0.693, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6, score=0.763, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6, score=0.693, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6, score=0.649, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6, score=0.746, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6, score=0.746, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6, score=0.714, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6, score=0.679, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6, score=0.750, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=1, n_estimators=100, min_child_weight=3, max_depth=10, learning_rate=0.001, gamma=0.01, colsample_bytree=0.6, score=0.679, total=   0.6s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6, score=0.675, total=   1.5s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6, score=0.772, total=   1.5s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6, score=0.702, total=   1.5s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6, score=0.675, total=   1.5s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6, score=0.737, total=   1.5s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6, score=0.746, total=   1.5s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6, score=0.714, total=   1.5s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6, score=0.679, total=   1.5s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6, score=0.759, total=   1.5s\n",
      "[CV] subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.7, reg_lambda=1, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=0.3, colsample_bytree=0.6, score=0.670, total=   1.5s\n",
      "[CV] subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6, score=0.684, total=   6.6s\n",
      "[CV] subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6, score=0.746, total=   6.7s\n",
      "[CV] subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6, score=0.684, total=   6.7s\n",
      "[CV] subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6, score=0.649, total=   6.6s\n",
      "[CV] subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6, score=0.658, total=   6.6s\n",
      "[CV] subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6, score=0.746, total=   6.7s\n",
      "[CV] subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6, score=0.732, total=   6.6s\n",
      "[CV] subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6, score=0.679, total=   6.6s\n",
      "[CV] subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6, score=0.723, total=   6.6s\n",
      "[CV] subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=1.5, reg_alpha=0, n_estimators=1000, min_child_weight=1, max_depth=7, learning_rate=0.01, gamma=0.3, colsample_bytree=0.6, score=0.616, total=   6.7s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0, score=0.684, total=   2.3s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0, score=0.772, total=   2.3s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0, score=0.684, total=   2.3s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0, score=0.667, total=   2.3s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0, score=0.711, total=   2.3s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0, score=0.737, total=   2.3s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0, score=0.741, total=   2.3s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0, score=0.661, total=   2.2s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0, score=0.732, total=   2.3s\n",
      "[CV] subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0 \n",
      "[CV]  subsample=0.7, reg_lambda=3, reg_alpha=0, n_estimators=250, min_child_weight=7, max_depth=10, learning_rate=0.01, gamma=0.3, colsample_bytree=1.0, score=0.670, total=   2.3s\n",
      "[CV] subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6, score=0.684, total=   1.2s\n",
      "[CV] subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6, score=0.754, total=   1.2s\n",
      "[CV] subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6, score=0.702, total=   1.0s\n",
      "[CV] subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6, score=0.658, total=   1.2s\n",
      "[CV] subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6, score=0.746, total=   1.2s\n",
      "[CV] subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6, score=0.746, total=   1.2s\n",
      "[CV] subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6, score=0.705, total=   1.0s\n",
      "[CV] subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6, score=0.696, total=   1.2s\n",
      "[CV] subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6, score=0.768, total=   1.2s\n",
      "[CV] subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6 \n",
      "[CV]  subsample=0.4, reg_lambda=2, reg_alpha=0.5, n_estimators=250, min_child_weight=7, max_depth=7, learning_rate=0.001, gamma=2, colsample_bytree=0.6, score=0.696, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.01\n",
      "Gamma:  2\n",
      "Max Depth:  2\n",
      "Subsample:  0.4\n",
      "Max Features at Split:  0.8\n",
      "Alpha:  1\n",
      "Lamda:  4.5\n",
      "Minimum Sum of the Instance Weight Hessian to Make a Child:  1\n",
      "Number of Trees:  100\n"
     ]
    }
   ],
   "source": [
    "# Create XGB Classifier object\n",
    "xgb_clf = xgb.XGBClassifier(tree_method = \"exact\", predictor = \"cpu_predictor\", verbosity = 1,\n",
    "                            objective = \"multi:softmax\")\n",
    "\n",
    "# Create parameter grid\n",
    "parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "               \"max_depth\": [2, 4, 7, 10],\n",
    "               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "               \"reg_alpha\": [0, 0.5, 1],\n",
    "               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "               \"min_child_weight\": [1, 3, 5, 7],\n",
    "               \"n_estimators\": [100, 250, 500, 1000]}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Create RandomizedSearchCV Object\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf, param_distributions = parameters, scoring = \"f1_micro\",\n",
    "                             cv = 10, verbose = 3, random_state = 40 )\n",
    "\n",
    "# Fit the model\n",
    "model_xgboost = xgb_rscv.fit(X_train, target_train)\n",
    "\n",
    "# Model best estimators\n",
    "print(\"Learning Rate: \", model_xgboost.best_estimator_.get_params()[\"learning_rate\"])\n",
    "print(\"Gamma: \", model_xgboost.best_estimator_.get_params()[\"gamma\"])\n",
    "print(\"Max Depth: \", model_xgboost.best_estimator_.get_params()[\"max_depth\"])\n",
    "print(\"Subsample: \", model_xgboost.best_estimator_.get_params()[\"subsample\"])\n",
    "print(\"Max Features at Split: \", model_xgboost.best_estimator_.get_params()[\"colsample_bytree\"])\n",
    "print(\"Alpha: \", model_xgboost.best_estimator_.get_params()[\"reg_alpha\"])\n",
    "print(\"Lamda: \", model_xgboost.best_estimator_.get_params()[\"reg_lambda\"])\n",
    "print(\"Minimum Sum of the Instance Weight Hessian to Make a Child: \",\n",
    "      model_xgboost.best_estimator_.get_params()[\"min_child_weight\"])\n",
    "print(\"Number of Trees: \", model_xgboost.best_estimator_.get_params()[\"n_estimators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Micro Average:  0.8166666666666667\n",
      "Test Accuracy:  0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective = \"multi:softmax\", learning_rate = 0.01, gamma = 2, max_depth = 2, subsample = 0.4,\n",
    "                           colsample_bytree = 0.8, reg_alpha = 1, reg_lambda = 4.5, min_child_weight = 1, n_estimators = 100\n",
    "                           ).fit(X_train, y_train) \n",
    "# Fit model\n",
    "xgb_model = xgb_clf.fit(X_train, target_train)\n",
    "# Predictions\n",
    "y_train_preds = xgb_model.predict(X_train)\n",
    "\n",
    "\n",
    "y_test_preds = xgb_model.predict(X_test)\n",
    "# Print F1 scores and Accuracy\n",
    "#print(\"Training F1 Micro Average: \", f1_score(target_train, y_train_preds, average = \"micro\"))\n",
    "print(\"Test F1 Micro Average: \", f1_score(target_test, y_test_preds, average = \"micro\"))\n",
    "print(\"Test Accuracy: \", accuracy_score(target_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see slight improvement in test accuracy with tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does this model help Big Mega accomplish their goal of increasing sales profit?\n",
    "\n",
    "The above model with 82% test accuracy shows that we Big Mega can predict the type of customers who are their best customers in terms of Recency, Frequency, and Monetary value.\n",
    "\n",
    "<li><b>High Value:</b> These customers make purchases frequently with higher amounts. They can be targeted with loyalty programs to incentivize them to shop more and fulfilling shopping experience</li>\n",
    "<li><b>Medium Value:</b> These shoppers have made moderately frequent and medium value purchases and can be targeted by providing them with offers and coupons to incentivize them to shop more with Big Mega </li>\n",
    "<li><b>Low Value:</b> These are cheap customers who come very less frequently and Big Mega can avoiding spending too much money in bringing these shoppers in as they aren't adding much value to the store. Infact they may have negative revenue that harms the business as the customer acquisition cost of these customers is higher than the value they provide </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do you think this data is appropriate for the objective?  What other data, if any, would you request from Big Mega?\n",
    "\n",
    "The data that was provided helped me successfully complete the objective of predicting the Life Time Value of a customer.\n",
    "<p> However, if I was provided with the Offers data by Big Mega, I could see how does the offer along with customer spending data affect the model. I could then pinpoint whether a particular offer is helping increase the LTV of high value customers and whether offers can lure Medium level customers more to drive the LTV up for these customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
